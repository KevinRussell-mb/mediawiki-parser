Goals
=====
* Possible (to represent MediaWiki syntax)
* Extensible per project (for {for} syntax, DekiWiki conditionals, etc.)

Parser libs
===========

LEPL
----
* Supports ambiguous grammars
o Idiosyncratic syntax with lots of operator overloading (even slices!)
o Slow (http://www.quora.com/What-is-the-best-parser-generator-for-Python/answer/Matthew-Lloyd)

PLY
---
. LALR or, optionally, SLR
* Modal lexer and parser. (Is this necessary? Understand what can't be BNF'd about apostrophe jungles and lists.)
* Easy to translate into C later
. Can turn off magic autodiscovery
o Potential for yacc to guess wrong about how to assemble symbols: reduce/reduce and shift/reduce errors
* Much faster than PLY? http://www.mefeedia.com/watch/29412150 at 23:58 suggests it's 5.5x faster. More benchmarks (ANTLR and more): http://www.dalkescientific.com/writings/diary/archive/2007/11/03/antlr_java.html
o A bit more verbose (but very clear)

PyParsing
---------
. Recursive descent (LL)
* Easier to write and debug?

Milestones
==========
* Understand what's so hard about apostrophes and lists (http://www.mediawiki.org/wiki/Markup_spec/BNF/Inline_text).
    This claims MW isn't context-free and has code on how to hack through the apostrophe jungle: http://web.archiveorange.com/archive/v/e7MXfq0OoW0nCOGyX0oa
    
    Useful background discussion by the folks who wrote the BNF attempt: http://www.mediawiki.org/wiki/Talk:Markup_spec
    The flex markup looks to have naive apostrophe jungle state rules: http://www.mediawiki.org/wiki/Markup_spec/flex
* Get a parse tree out of a lib.
* Think about extensibility
* Get apostrophes working (to test ambiguity support).
* Implement productions, tag by tag

Notes
=====
LR good. LALR even better.
If we build the parse tree in custom lexer callbacks, we can make it an ElementTree or whatever we want--meaning we can use XPath on it later if we want.